---
layout: default
title: Machine Learning in Action::k-近邻算法（kNN）
---

<h2>{{ page.title }}</h2>

<hr />

<h3> kNN-概述 </h3>

<pre>
	关键词：分类·监督学习

	原理：基于特征距离的最相近样本的等权重投票制。
	简单来讲：存在一个样本数据集合（训练集），样本中的每一条数据都存在一个标签（所属分类）。预测数据集合是仅有特征数据没有标签的数据集合。
		对于预测集的每一条数据，我们均可以将其与样本集合中的数据在特征空间进行距离计算，挑选出与之距离最相近的K个样本数据。然后这K个
		样本数据中，出现次数最多的分类即为我们要预测的那个分类。
	缺点：显而易见，计算的时间复杂度与空间复杂度均较高。
</pre>

<hr />

<h3> kNN-算法实现 </h3>

<pre>
函数说明：
	kNN 主体算法
输入参数：
	intX : 预测数据（特征向量） : list
	dataSet ： 训练集（特征向量集） : array
	labels : 训练集对应的标签（类型向量） : list
	k : 投票个体数 : int
返回参数：
	预测结果：最有可能的分类 : str
</pre>

<code>
<pre>
def classify0(intX,dataSet,labels,k):

	#计算距离（此处采用的是欧式距离）
	dataSetSize = dataSet.shape[0]
	diffMat = tile(intX,(dataSetSize,1)) - dataSet
	sqDiffMat = diffMat**2
	sqDistances = sqDiffMat.sum(axis = 1)
	distances = sqDistances**0.5

	#选择距离最小的K个点
	sortedDistIndicies = distances.argsort()
	classCount = {}
	for i in range(k):
		voteILabel = labels[sortedDistIndicies[i]]
		classCount[voteILabel] = classCount.get(voteILable,0) + 1

	#排序
	sortedClassCount = sorted(classCount.iteritems(),key = operator.itemgetter(1),reverse=True)
	return sortedClassCount[0][0]

</pre>
</code>

<hr/>


<p> Welcome to contact <a href="mailto:jangwee1@sina.com.cn">me</a>,the friends who like Machine-Learning and Data-Mining.</p>
<p> <a href=freedom.png>:)</a></p>

<p>{{ page.date | date_to_string }}</p>

