---
layout: default
title: Machine Learning in Action::Decision Tree(DT)
---

<h2>{{ page.title }}</h2>

<hr />

<h3> DT-概述 </h3>

<pre>
	关键词：分类·监督学习
	
	原理：基于特征的信息比重，进行规则提取。进而用于决策。
	简单来讲：存在一个样本数据集合（训练集），样本中的每一条数据都存在一个标签（所属分类）。预测数据集合是仅有特征数据没有标签的数据集合。
		我们首先对样本集合的数据进行分析，构造出一颗树，树的叶子节点为标签（终止节点），非叶子节点为特征（判断模块）。
		首先，选取一个特征作为判断模块，该特征能“足够好”的将原集合划分成若干较小的集合。对划分后的较小集合，如果集合中的元素均属同一类别（或者
		没有特征可以继续划分），则终止，该终止节点的属性为该类别（或者集合中最多的类别）；否则对较小集合进行继续选取剩余特征，划分，递归下去。
		最终形成一个树。当拿到预测集合的数据时，从根节点（最重要节点）的特征进行匹配，依次往下，直到到达所属分类，即为预测分类。
	优缺点：计算复杂度不高，结果易于理解，对中间值缺失不敏感，可处理不相关特征数据。适用于专家系统。
		但可能会产生overfitting
</pre>

<hr />

<h3> DT-核心算法实现 </h3>

<pre>
函数名称： 
	createTree(dataSet,labels)
函数说明：
	递归创建决策树
输入参数：
	dataSet : 训练集（特征向量+类别） ： array
	labels : 特征向量名称 ： list
返回参数：
	返回构造的决策树 ： dict 

def createTree(dataSet,labels):
	
	#获取训练集样本的类别
	classList = [example[-1] for example in dataSet]
	
	#集合是否属于一类：
	if classList.count(classList[0]) == len(classList):
		return labels
	#判断是否只剩下一个特征：
	if len(dataSet[0]) == 1:
		return majorityCnt(classList)

	#均不是以上两种情况，选取最好特征进行分类
	bestFeatIndex = chooseBestFeatureToSplit(dataSet)
	bestFeatLabel = labels[bestFeatIndex]
	#构建一个决策模块
	myTree = {bestFeatLabel:{}}
	del(labels[bestFeatIndex])
	#获取决策模块的分支情况
	featValues = [example[bestFeatIndex] for example in dataSet]
	uniqueVals = set(featValues)
	#创建该节点下的所有分支
	for value in uniqueVals:
		#Python传引用，避免破坏，clone一份
		subLabels = labels[:]
		#创建其中一个value对应的分支
		myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet,bestFeat,value),subLabels)
	
	return myTree

-------------------------------------------------------------------------------------------------------------------------
函数名称：
	classify(inputTree,featLabels,testVec)
函数说明：
	递归的寻找最有可能的分类标签
输入参数：
	inputTree : 构建的决策树 ： dict
	featLabels : 预测数据的特征名称 ： list
	teseVec : 预测数据的特征值（与featLabels对应） ： list 
返回参数：
	预测的分类

def classify(inputTree,featLabels,testVec):
	
	#获取根判断模块的feature
	firstStr = inputTree.keys()[0]
	#获取判决模块下的森林（集合）
	secondDict = inputTree[firstStr]
	#获取预测数据的对应的该判决模块在featLabels中的位置，便于取值
	featIndex = featLabels.index(firstStr)
	
	#遍历森林，找对应的树
	for key in secondDict.keys():
		if key == testVec[featIndex]:
			#该value对应的是一颗树（未到分类节点），继续递归
			if type(secondDict[key]).__name__ == "__dict__":
				classLabel = classify(secondDict[<strong>key</strong>],featLabels,testVec)
			#否则到达分类节点
			else:
				classLabel = secondDict[key]
		return classLabel


-------------------------------------------------------------------------------------------------------------------------











-------------------------------------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------------------------------------


















	
</pre>



